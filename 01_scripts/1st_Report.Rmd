---
title: '**First Part: COVID-19 in Spain**'
subtitle: '**Advanced Regression And Prediction**'
author: '*Roberto Jes√∫s Alcaraz Molina*'
date: "09/05/2021"
output:
  pdf_document:
    latex_engine: xelatex
    number_section: true
    highlight: tango
    fig_caption: yes
    toc: true
    # toc_depth: 4
header-includes: 
- \usepackage{float}
- \usepackage{amsbsy}
- \usepackage{amsmath}
- \usepackage{graphicx}
- \usepackage{subfig}
- \usepackage{booktabs}
bibliography: references.bib
---

```{=tex}
\begin{center}
\includegraphics[width=3in]{logouc3m}
\end{center}
```
\newpage

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      echo = F, 
                      message = FALSE,
                      eval = T,
                      fig.pos="H", 
                      fig.align="center",
                      fig.width=11,
                      cache=FALSE, error = TRUE)
```

```{r, echo = F}
# Model packages
pacman::p_load(ranger, mixOmics, plsmod)

# Packages
# devtools::install_github("stevenpawley/recipeselectors")
pacman::p_load(COVID19, tidymodels, rsample, recipes, parsnip, 
               yardstick, workflows, tune, patchwork, lubridate, recipeselectors,
               doParallel, tidyquant, finetune, ggpubr, MASS)
library(tidyverse, attach.required = T)
# For ggplot
theme_set(theme_tq())

# spain <- covid19(country = "spain", start = "2020-01-22", end = "2021-04-11")
# spain_new_data <- covid19(country = "spain", start = "2021-04-11", end = "2021-05-02")

# saveRDS(spain, "00_data/spain.RDS")
# saveRDS(spain_new_data, "00_data/spain_new_data.RDS")
```



# INTRODUCTION

The aim of this project is to analyze and try to predict the confirmed cases and 
deaths due to the coronavirus pandemic (COVID-19) in Spain using regression tools.
It started the 31st of January of 2020 in La Gomera (Canary Island) and continues
until now, having almost 2.5 million confirmed cases and around 67k deaths.

All the analysis of this project, from the data cleaning until the model results
will be done mainly with the `tidyverse` [@tidyverse] and `tidymodels` [@tidymodels]
packages. The first one is well known for `R` users but the second, even though 
is still in development, has enough tools for modeling and machine learning.

In the second section, we will see from where we obtained the data and how to clean
it. In the third one, we will explore our data by doing some visualizations and
we will think about how to adress the problem. In the fourth one, we will do some
feature engineering, i.e., we will modify and create some variables, divide our
training data into folds to compare our models, and many other necessary steps 
before start modeling. In the next one, we will tune our model parameters and fit
the models. Finally, in the last section, we will select the best model and say
some conclusions.

```{r}
spain <- readRDS("../00_data/spain.RDS")
spain_new_data <- readRDS("../00_data/spain_new_data.RDS")
```

\bigskip
# DATA CLEANING

The data has been taken from the R package `COVID19` [@guidotti2020]. This COVID-19
data set contain 446 observations, which are the days from the 22nd of January 2020
until the 11th of March 2021, with 36 variables divided in 5 categories: *identifiers*,
*COVID-19 variables*, *policy measures*, *geographic information* and *external keys*.

Regarding the identifiers, we will select only date. In the second group, we have
variables related with the COVID-19 such as the cumulative number of deaths, confirmed
cases, test, etc. For the moment, we will select all of them and then we will decide.
In the policy measures, we have very important variables for the development of 
the pandemic and for our study, like `workplace_closing`, `stay_home_restrictions`
or `internal_movement_restrictions`, so we must take them into account. Finally,
there are other geographical variables that could be interesting for our models.
A description of our variables can be seen below:

```{r, eval=F}
skimr::skim(spain)
```

```{r}
population <- spain$population[1]
spain <- spain %>%
  dplyr::select(date, deaths, confirmed, vaccines, hosp, icu, stay_home_restrictions,
         school_closing, workplace_closing, transport_closing, gatherings_restrictions,
         internal_movement_restrictions)
spain <- spain[, -1]

spain_new_data <- spain_new_data %>%
  dplyr::select(date, deaths, confirmed, vaccines, hosp, icu, stay_home_restrictions,
         school_closing, workplace_closing, transport_closing, gatherings_restrictions,
         internal_movement_restrictions)
spain_new_data <- spain_new_data[, -1]
```

| **Variable**                     | **Description**                                          |
|:---------------------------------|----------------------------------------------------------|
| `id`                             | Unique identifier.                                       |
| `date`                           | Observation date.                                        |
| `deaths`                         | Cumulative number of deaths.                             |
| `test`                           | Cumulative number of test.                               |
| `confirmed`                      | Cumulative number of confirmed cases.                    |
| `vaccines`                       | Cumulative number of doses administered (single dose).   |
| `hosp`                           | Number of hospitalized patients on date.                 |
| `icu`                            | Number of hospitalized patients in ICUs on date.         |
| `population`                     | Total population.                                        |
| `stay_home_restrictions`         | Indicates the measures of staying at home.               |
| `school_closing`                 | Indicates the measures in education.                     |
| `workplace_closing`              | Indicates the measures of the workplace.                 |
| `transport_closing`              | Indicates the measures in the public transport.          |
| `gatherings_restrictions`        | Indicates the measures of gatherings.                    |
| `internal_movement_restrictions` | Indicates the measures of the movements between regions. |


We have realized that all numerical variables have **missing values**. Some of 
them like the deaths or confirmed cases have them at the beginning, but we have
no problem with that because there were not any cases at that time, so we will 
give 0 to these values. However, there are other variables for which we have to 
think what to do with their missing values very carefully. For instance, for the
tests, there are 399 missing values out of 451 observations, so we will remove 
it because there is no much information. For the vaccines, we have 378, which we
might expect that since the first day we had vaccines was the 3rd of January of 
2021 but also, we have some of them in the weekends. For the number of hospitalized
people and the ICU people, we have again 303 NAs, but for the moment they will 
remain in the data set. How to deal with these variables that have missing values
will be seen in next sections. Finally, the variables for the measures do not have
any missing value.

```{r}
spain <- spain %>%
  mutate(
    deaths = replace(deaths, is.na(deaths), 0),
    confirmed = replace(confirmed, is.na(confirmed), 0)
  )
spain$vaccines[1:348] <- 0
```

After that, we should modify our categorical variables, since they are encoded as
integers:

- The first one, `stay_home_restrictions`, will have three categories: no measures,
require not leaving house with exceptions (e.g: exercise) and not leaving the house. 

- The next one, `school_closing` has another four categories: no measures, recommended
closing, require closing for some schools and require closing. 

- For `workplace_closing` we have no measures, recommended closing, require closing
for some sectors and require closing. 

- For `transport_closing` we have two levels: no measures and recommended closing. 

- For `gatherings_restrictions`: no measures, restrictions between 10-100 people 
and restrictions on gatherings of less than 10 people. 

- Finally, the variable `internal_movement_restrictions` has no measures, recommend
closing or require closing.

```{r}
spain <- spain %>%
  mutate(
    stay_home = factor(stay_home_restrictions, 
                       levels = c(0, 1, 2),
                       labels = c("no", "recommended", "mandatory")),
    
    school_closing = factor(school_closing, 
                            levels = c(0, 1, 2, 3),
                            labels = c("no", "recommended", "require", "mandatory")),
    
    workplace_closing = factor(workplace_closing, 
                               levels = c(0, 1, 2, 3),
                               labels = c("no", "recommended", "require", "mandatory")),
    
    transport_closing = factor(transport_closing, 
                               levels = c(0, 1),
                               labels = c("no", "recommended")),
    
    gatherings_restrictions = factor(gatherings_restrictions, 
                                     levels = c(0, 1, 2, 3, 4),
                                     labels = c("no", "no", "no", "10-100", "<10")),
    
    internal_movement_restrictions = factor(internal_movement_restrictions, 
                                            levels = c(0, 1, 2),
                                            labels = c("no", "recommended", "mandatory")),
  ) %>%
  dplyr::select(-stay_home_restrictions)

spain_new_data <- spain_new_data %>%
  mutate(
    stay_home = factor(stay_home_restrictions, 
                       levels = c(0, 1, 2),
                       labels = c("no", "recommended", "mandatory")),
    
    school_closing = factor(school_closing, 
                            levels = c(0, 1, 2, 3),
                            labels = c("no", "recommended", "require", "mandatory")),
    
    workplace_closing = factor(workplace_closing, 
                               levels = c(0, 1, 2, 3),
                               labels = c("no", "recommended", "require", "mandatory")),
    
    transport_closing = factor(transport_closing, 
                               levels = c(0, 1),
                               labels = c("no", "recommended")),
    
    gatherings_restrictions = factor(gatherings_restrictions, 
                                     levels = c(0, 1, 2, 3, 4),
                                     labels = c("no", "no", "no", "10-100", "<10")),
    
    internal_movement_restrictions = factor(internal_movement_restrictions, 
                                            levels = c(0, 1, 2),
                                            labels = c("no", "recommended", "mandatory")),
  ) %>%
  dplyr::select(-stay_home_restrictions)
```

After these changes, in the next section we will perform some visualizations to 
know the distributions of the variables, relationship between them, etc.

\bigskip
# EXPLORATORY DATA ANALYSIS (EDA)

Our two main variables of interest are cumulative `deaths` and `confirmed` cases.
First of all, let's see how they are distributed.

```{r, fig.cap="Cumulative deaths and confirmed cases in Spain"}
p1 <- spain %>%
  ggplot(aes(x = date, y = deaths)) +
  geom_line()

p2 <- spain %>%
  ggplot(aes(x = date, y = confirmed)) +
  geom_line()

ggarrange(p1, p2) +
  ggtitle("Cumulative deaths and confirmed cases") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))
```

As we can observe, there are some mistakes in the data: in the cumulative deaths,
there is a drop around June, and in the cumulative confirmed cases, there is another
drop in February, which do not make any sense since we are considering **cumulative**
cases. Therefore, to fix that error, for all days that has a lower value than their
previous day, we will assign the value of their previous day to that day.

```{r}
for (i in 1:(nrow(spain)-1)){
  if (spain$deaths[i+1] < spain$deaths[i]) spain$deaths[i+1] <- spain$deaths[i]
  if (spain$confirmed[i+1] < spain$confirmed[i]) spain$confirmed[i+1] <- spain$confirmed[i]
}
```

```{r, fig.cap="Cumulative deaths and confirmed cases fixed"}
p1 <- spain %>%
  ggplot(aes(x = date, y = deaths)) +
  geom_line()

p2 <- spain %>%
  ggplot(aes(x = date, y = confirmed)) +
  geom_line()

ggarrange(p1, p2) +
  ggtitle("Cumulative deaths and confirmed cases fixed") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))
```

Now let's focus on the vaccines administered and the hospitalized people:

```{r, fig.cap="Cumulative vaccines, number of hospitalized people and number of patients in ICUs on date"}
p1 <- spain %>%
  ggplot(aes(x = date, y = vaccines)) +
  geom_line(na.rm = T)

p2 <- spain %>%
  ggplot(aes(x = date, y = hosp)) +
  geom_line(na.rm = T)

p3 <- spain %>%
  ggplot(aes(x = date, y = icu)) +
  geom_line(na.rm = T)

p1 + p2 + p3
```

Due to the missing values, we have discontinuous plots. For `vaccines`, these missing
values appear because there are some places in Spain where the vaccination is stopped
on weekends, or because these data is not recorded on weekends. Hence, as we have
done before for the deaths and confirmed cases, we will take the value from the
day before. However, for the other two variables, there is no information prior 
to July, so we will not take them into account because it is not realistic.

```{r}
for (i in 1:nrow(spain)-1){
  if (is.na(spain$vaccines[i+1])) spain$vaccines[i+1] <- spain$vaccines[i]
}

spain <- spain %>%
  dplyr::select(-hosp, -icu)

spain_new_data$vaccines[1] <- 10784997 # we take the data from the previous day
for (i in 1:nrow(spain_new_data)-1){
  if (is.na(spain_new_data$vaccines[i+1])) spain_new_data$vaccines[i+1] <- spain_new_data$vaccines[i]
}

spain_new_data <- spain_new_data %>%
  dplyr::select(-hosp, -icu)
```

Then, we are going to see the relationships between our target variables, deaths
and confirmed cases, and some of the categorical predictors. Below, we can see how
predictors like `stay_home`, `workplace_closing`, `gatherings_restrictions` and `internal_movement_restrictions` are related with the confirmed cases:

```{r, fig.cap="Relationship between the cumulative confirmed cases and some categorical variables", fig.width=8.7}
p1 <- spain %>%
  ggplot(aes(x = date, y = confirmed, color = stay_home)) +
  labs(y = " ", x = "") + 
  geom_point()

p2 <- spain %>%
  ggplot(aes(x = date, y = confirmed, color = workplace_closing)) +
  labs(y = " ") + 
  geom_point()

p3 <- spain %>%
  ggplot(aes(x = date, y = confirmed, color = gatherings_restrictions)) +
  labs(y = " ", x = "") + 
  geom_point()

p4 <- spain %>%
  ggplot(aes(x = date, y = confirmed, color = internal_movement_restrictions)) +
  labs(y = " ") + 
  geom_point()

ggarrange(p1, p3, p2, p4, ncol = 2, nrow = 2) +
  ggtitle("Cumulative confirmed cases") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))
```

The first plot in the top left corner shows us that the variable `stay_home` is 
wrongly collected, since it was not mandatory to stay at home after the summer, 
so we must change it. Also, we can observe how after the summer the measures were
much more restrictives than during the summer because of the increment of new cases.
For the cummulative deaths, we can see it below: 

```{r}
spain$stay_home[278:nrow(spain)] <- "recommended"
spain_new_data$stay_home <- "recommended"
```


```{r, fig.cap="Relationship between the cumulative deaths and some categorical variables", fig.width=8.7}
p1 <- spain %>%
  ggplot(aes(x = date, y = deaths, color = stay_home)) +
  labs(y = " ", x = "") +
  geom_point()

p2 <- spain %>%
  ggplot(aes(x = date, y = deaths, color = workplace_closing)) +
  labs(y = " ") +
  geom_point()

p3 <- spain %>%
  ggplot(aes(x = date, y = deaths, color = gatherings_restrictions)) +
  labs(y = " ", x = "") +
  geom_point()

p4 <- spain %>%
  ggplot(aes(x = date, y = deaths, color = internal_movement_restrictions)) +
  labs(y = " ") +
  geom_point()

ggarrange(p1, p3, p2, p4, ncol = 2, nrow = 2) +
  ggtitle("Cumulative deahts") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))
```

Again, after summer the measures become more agressive due to the new cases. In 
the following section, we will see how to modify some variables after we have more
knowledge about them.


\bigskip
# FEATURE ENGINEERING

\bigskip
In this section, based on the previous analysis of the variables, we should decide
which changes should be done in our data. Firslty, since our variables of interest,
deaths and confirmed cases, are cumulative and daily, we will aggregate them to 
have the **number of deaths and confirmed cases by week**. This decision has been
taken because there are too much noise in daily data due to different human errors
that appear when this data is collected, so taking the data weekly allow us to 
predict in a better way the future.

On the one hand, to obtain the number of deaths, confirmed cases and vaccines per
week, we will compute firstly the daily cases, substracting today's cases minus 
tomorrow's, and then we will add all the cases of the week. On the other hand, for
the categorical variables, we will compute the mode of the variables in every week,
i.e., we will give the most frequent values to every week.

```{r}
calculate_mode <- function(x) {
  uniqx <- unique(x)
  uniqx[which.max(tabulate(match(x, uniqx)))]
}

spain <- spain %>%
  mutate(
    new_date = as.Date(cut(date, "week")),
    deaths_day = spain$deaths - lag(spain$deaths),
    confirmed_day = spain$confirmed - lag(spain$confirmed),
    vaccines_day = spain$vaccines - lag(spain$vaccines)
  ) %>%
  group_by(date) %>%
  summarise(
    new_date = new_date,
    date = date,
    deaths_week = sum(deaths_day),
    confirmed_week = sum(confirmed_day),
    vaccines_week = sum(vaccines_day),
    school_closing = calculate_mode(school_closing),
    workplace_closing = calculate_mode(workplace_closing),
    gatherings_restrictions = calculate_mode(gatherings_restrictions),
    stay_home = calculate_mode(stay_home),
    internal_movement_restrictions = calculate_mode(internal_movement_restrictions)
  ) %>%
  ungroup() %>%
  filter(date %in% new_date) %>%
  dplyr::select(-new_date)


spain_new_data <- spain_new_data %>%
  mutate(
    new_date = as.Date(cut(date, "week")),
    deaths_day = spain_new_data$deaths - lag(spain_new_data$deaths),
    confirmed_day = spain_new_data$confirmed - lag(spain_new_data$confirmed),
    vaccines_day = spain_new_data$vaccines - lag(spain_new_data$vaccines)
  ) %>%
  group_by(date) %>%
  summarise(
    new_date = new_date,
    date = date,
    deaths_week = sum(deaths_day),
    confirmed_week = sum(confirmed_day),
    vaccines_week = sum(vaccines_day),
    school_closing = calculate_mode(school_closing),
    workplace_closing = calculate_mode(workplace_closing),
    gatherings_restrictions = calculate_mode(gatherings_restrictions),
    stay_home = calculate_mode(stay_home),
    internal_movement_restrictions = calculate_mode(internal_movement_restrictions)
  ) %>%
  ungroup() %>%
  filter(date %in% new_date) %>%
  dplyr::select(-new_date)
```

Now that we have prepared our data, we have to think about what **preprocessing**
steps should we do. These are some changes that we have to apply to our data before
we start fitting the models. Our preprocessing steps will be:
\bigskip


1. Divide the date in month and year and convert it to categorical, because they
could be very important for the outcomes.

```{r}
spain <- spain %>%
  mutate(
    month = factor(month(date)),
    year = factor(year(date))
  )

spain_new_data <- spain_new_data %>%
  mutate(
    month = factor(month(date)),
    year = factor(year(date))
  )
```

2. Since we want to predict the deaths and confirmed cases in the following weeks,
we should take into account how many deaths and confirmed cases were the weeks 
before. Therefore, we will create some new variables which will be the deaths and
confirmed cases 3 weeks lagged, i.e., we will consider in our model what happened
in the previous weeks to be able to predict in a better way the next month.

```{r}
spain <- spain %>%
  mutate(
    lag_3_deaths_week = lag(deaths_week, n = 3),
    lag_3_confirmed_week = lag(confirmed_week, n = 3)
  ) %>%
  drop_na()

spain_new_data <- spain_new_data %>%
  mutate(
    lag_3_deaths_week = tail(spain$deaths_week, 3),
    lag_3_confirmed_week = tail(spain$confirmed_week, 3)
  )
```

3. Before starting fitting models, we should take a look to our predictors. We have
12 covariates which the majority of them are categorical, so we must do **feature selection**.
To do that, we will use the package `recipeselectors` [@recipeselector], which adds
some feature selection methods to the `recipes` package (from `tidymodels`) such
as variable importance or boluta methods. This time we will use recursive feature
elimination, selecting the features that are above the 20% of importance using a
random forest model. For the model that predicts the deaths per week, it removes
the variables `stay_home` and `gathering_restrictions`, nonetheless, for the confirmed
cases, it removes `workplace_closing` and again `gathering_restrictions`.

```{r}
rfe_model <- rand_forest() %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("regression")

# Predictive model for the deaths
set.seed(1234)
select_rec_deaths <- 
  recipe(deaths_week ~ ., data = spain) %>%
  step_rm(date) %>%
  step_select_vip(all_predictors(), outcome = "deaths_week", model = rfe_model, threshold = 0.2)

spain_deaths <- select_rec_deaths %>% prep() %>% juice()
spain_deaths <- spain_deaths %>%
  mutate(date = spain$date)

# Predictive model for the confirmed cases
select_rec_confirmed <- 
  recipe(confirmed_week ~ ., data = spain) %>%
  step_rm(date) %>%
  step_select_vip(all_predictors(), outcome = "confirmed_week", model = rfe_model, threshold = 0.2)


spain_confirmed <- select_rec_confirmed %>% prep() %>% juice()
spain_confirmed <- spain_confirmed%>%
  mutate(date = spain$date)

# head(select_rec %>% prep() %>% juice())
```


4. Even though we will **test** our data with the next 3 weeks, we should divide
our training data into folds to tune the model parameters and to compare them. To
do that, there is a function called `rolling_origin` from the `rsample` package
(from `tidymodels`) which can divide our training set into different folds by date,
which is very useful for time series models. We will get 10 folds where the analysis
set will be the first 12 weeks, and the assessment set, the following 3. This method
will allow us to tune the different parameters of our models and get the best with
the lowest prediction error. After selecting the two best ones, we will again fit
the models in all our training set and then, we will see how it works in our test
set.

```{r}
set.seed(123)
spain_rolling_deaths <- rolling_origin(
  spain_deaths, 
  initial = 12, # number of weeks used to train in each resample
  assess = 3, # number of weeks used to validate in each resample
  cumulative = F,
  skip = 4
  )

spain_rolling_confirmed <- rolling_origin(
  spain_confirmed, 
  initial = 12, # number of weeks used to train in each resample
  assess = 3, # number of weeks used to validate in each resample
  cumulative = F,
  skip = 4
  )

# analysis(spain_rolling$splits[[1]])
# assessment(spain_rolling$splits[[1]])
```

5. Finally, it is time to use the `recipes` package [@recipes] to do the preprocessing
steps that the models need. For the linear regression models (`lm`, `ridge`, `lasso` and `elastic net`), the recommended preprocessing is to remove the zero variance variables, decorrelate the predictors and create dummy variables for the categorical predictors; and for the partial least squares (PLS), we need to normalize the predictors, i.e., transform them to have mean equal to 0 and variance equal to 1.

```{r}
# Recipes for the deaths model
basic_rec_deaths <- 
  recipe(deaths_week ~ ., data = spain_deaths) %>%
  step_rm(date) # we remove the variable date

linear_reg_rec_deaths <- 
  basic_rec_deaths %>%
  step_nzv(all_numeric_predictors(), freq_cut = 65/5) %>% # remove the zero variance variables
  step_corr(all_numeric_predictors(), threshold = 0.65) %>% # decorrelate predictors
  step_dummy(all_nominal_predictors())# get dummy variables

  
  
pls_rec_deaths <- 
  basic_rec_deaths %>%
  step_nzv(all_numeric_predictors(), freq_cut = 65/5) %>% # remove the zero variance variables 
  step_normalize(all_numeric_predictors()) %>% # center and scale
  step_dummy(all_nominal_predictors()) # get dummy variables



# Recipes for the confirmed model
basic_rec_confirmed <- 
  recipe(confirmed_week ~ ., data = spain_confirmed) %>%
  step_rm(date) # we remove the variable date

linear_reg_rec_confirmed <- 
  basic_rec_confirmed %>%
  step_nzv(all_numeric_predictors(), freq_cut = 65/5) %>% # remove the zero variance variables
  step_corr(all_numeric_predictors(), threshold = 0.65) %>% # decorrelate predictors
  step_dummy(all_nominal_predictors()) # get dummy variables

  
  
pls_rec_confirmed <- 
  basic_rec_confirmed %>%
  step_nzv(all_numeric_predictors(), freq_cut = 65/5) %>% # remove the zero variance variables 
  step_normalize(all_numeric_predictors()) %>% # center and scale
  step_dummy(all_nominal_predictors()) # get dummy variables
```

\bigskip
After defining all these steps, we are able to start creating our models. In the next section, we are going to explain the models we are going to analyze as well as all the steps that need to be followed to create a good model.

\newpage
# MODEL TUNING AND VALIDATION

\bigskip
As we have said in the previous section, we are going to try 6 different models:
\bigskip

- Simple and robust linear models (`lm` and `rlm`). Since the robust linear model
is not implemented in the `parsnip` package, it has been created. In the script
`rlm.R` there is the implementation of the model.

- Three different models from the `glmnet` package: ridge, lasso and elastic net
regression. The difference between these three models is the parameter tuning. We
have two parameters to tune: `penalty`, which represents the total amount of 
regularization, and `mixture`, which is a number between 0 and 1 that indicates 
the proportion of L1 regularization in the model. When `mixture = 0`, we get
a ridge model but when `mixture = 1` we get a lasso model. When we decide to 
tune also the `mixture` parameter, then we get a elastic net model.

- A partial least squares model (`PLS`), when we have to tune two parameters: 
`predictor_prop`, which is the proportion of predictors that are allowed to affect
each PLS component, and `num_comp`, which is the number of PLS components.


```{r}
# Models
lm_model <- 
  linear_reg() %>%
  set_engine("lm")
  
ridge_model <- 
  linear_reg(penalty = tune(), mixture = 0) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

lasso_model <- 
  linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

elastic_net_model <- 
  linear_reg(penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

pls_model <-
  pls(predictor_prop = tune(), num_comp = tune()) %>%
  set_engine('mixOmics') %>%
  set_mode('regression')
```

```{r, eval=F}
# Now, we can start by defining the robust linear model.
# There is some problems with doing parallel processing 
# with new models. Therefore, we will fit it before.

source("rlm.R")

rlm_model <- 
  linear_reg() %>%
  set_engine("rlm")

r_linear_reg_rec_deaths <- 
  basic_rec_deaths %>%
  step_dummy(all_nominal_predictors()) %>% # get dummy variables
  step_nzv(all_numeric_predictors(), freq_cut = 65/5) %>% # remove the zero variance variables
  step_corr(all_numeric_predictors(), threshold = 0.65) # decorrelate predictors

r_linear_reg_rec_confirmed <- 
  basic_rec_confirmed %>%
  step_dummy(all_nominal_predictors()) %>% # get dummy variables
  step_nzv(all_numeric_predictors(), freq_cut = 65/5) %>% # remove the zero variance variables
  step_corr(all_numeric_predictors(), threshold = 0.65) # decorrelate predictors
  

# Deaths
rlm_deaths_wf <- 
  workflow() %>%
  add_recipe(r_linear_reg_rec_deaths) %>%
  add_model(rlm_model)

rlm_deaths_resamples <-
  rlm_deaths_wf %>%
  fit_resamples(
    spain_rolling_deaths,
    control = control_resamples(save_pred = T, 
                                save_workflow = T)
  )

# Confirmed
rlm_confirmed_wf <- 
  workflow() %>%
  add_recipe(r_linear_reg_rec_confirmed) %>%
  add_model(rlm_model)

rlm_confirmed_resamples <-
  rlm_confirmed_wf %>%
  fit_resamples(
    spain_rolling_confirmed,
    control = control_resamples(save_pred = T, 
                                save_workflow = T)
  )
```


\bigskip
Thanks to the `workflowsets` package [@workflowsets], we can create two sets of
**workflows** (pipelines in python), one for the deaths model and the other for 
the confirmed cases. A workflow is an object which is formed by a recipe and a model. 

```{r}
# Deaths
workflow_tune_deaths <- workflow_set(
  preproc = list(
    linear_reg_deaths = linear_reg_rec_deaths,
    pls_deaths        = pls_rec_deaths
  ),
  models = list(
    lm_wf            = lm_model,
    ridge_wf         = ridge_model,
    lasso_wf         = lasso_model,
    elastic_net_wf   = elastic_net_model,
    model_wf         = pls_model
  ), 
  cross = T
)

workflow_tune_deaths <- workflow_tune_deaths %>%
  filter(wflow_id == c("linear_reg_deaths_lm_wf", "linear_reg_deaths_ridge_wf", "linear_reg_deaths_lasso_wf", "linear_reg_deaths_elastic_net_wf", "pls_deaths_model_wf"))

# Confirmed
workflow_tune_confirmed <- workflow_set(
  preproc = list(
    linear_reg_confirmed = linear_reg_rec_confirmed,
    pls_confirmed        = pls_rec_confirmed
  ),
  models = list(
    lm_wf            = lm_model,
    ridge_wf         = ridge_model,
    lasso_wf         = lasso_model,
    elastic_net_wf   = elastic_net_model,
    model_wf         = pls_model
  ), 
  cross = T
)

workflow_tune_confirmed <- workflow_tune_confirmed %>%
  filter(wflow_id == c("linear_reg_confirmed_lm_wf", "linear_reg_confirmed_ridge_wf", "linear_reg_confirmed_lasso_wf", "linear_reg_confirmed_elastic_net_wf", "pls_confirmed_model_wf"))
```


After defining these models, it is time to tune their parameters. With the R package
`doParallel` [@doParallel], we are able to select the number of cores in order to
decrease the computational time. In my computer, using 8 cores instead of 4 decreases
more than half the computational time, which helps a lot. Next, we modify the intervals
of the model parameters, and we will select the set of them that minimizes the root
mean square error (`rmse`) and the ordinal r-square (`rsq`). Below, we can see the
results for the deaths model:


```{r, eval=F}
# Deaths
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      save_workflow = TRUE
   )

workflow_results_deaths <- workflow_tune_deaths %>%
  workflow_map(
    seed = 1503,
    resamples = spain_rolling_deaths,
    grid = 50,
    control = grid_ctrl,
    verbose = T
   )

# i	No tuning parameters. `fit_resamples()` will be attempted
# i 1 of 5 resampling: linear_reg_deaths_lm_wf
# v 1 of 5 resampling: linear_reg_deaths_lm_wf (10.4s)
# i 2 of 5 tuning:     linear_reg_deaths_ridge_wf
# v 2 of 5 tuning:     linear_reg_deaths_ridge_wf (3.2s)
# i 3 of 5 tuning:     linear_reg_deaths_lasso_wf
# v 3 of 5 tuning:     linear_reg_deaths_lasso_wf (2.9s)
# i 4 of 5 tuning:     linear_reg_deaths_elastic_net_wf
# v 4 of 5 tuning:     linear_reg_deaths_elastic_net_wf (1m 11.1s)
# i 5 of 5 tuning:     pls_deaths_model_wf
# v 5 of 5 tuning:     pls_deaths_model_wf (1m 11.1s)

stopCluster(cl)

# saveRDS(workflow_results_deaths, "workflow_results_deaths.RDS")

# Confirmed
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      save_workflow = TRUE
   )

workflow_results_confirmed <- workflow_tune_confirmed %>%
  workflow_map(
    seed = 1503,
    resamples = spain_rolling_confirmed,
    grid = 50,
    control = grid_ctrl,
    verbose = T
   )

# i	No tuning parameters. `fit_resamples()` will be attempted
# i 1 of 5 resampling: linear_reg_confirmed_lm_wf
# v 1 of 5 resampling: linear_reg_confirmed_lm_wf (11.5s)
# i 2 of 5 tuning:     linear_reg_confirmed_ridge_wf
# v 2 of 5 tuning:     linear_reg_confirmed_ridge_wf (3.2s)
# i 3 of 5 tuning:     linear_reg_confirmed_lasso_wf
# v 3 of 5 tuning:     linear_reg_confirmed_lasso_wf (3s)
# i 4 of 5 tuning:     linear_reg_confirmed_elastic_net_wf
# v 4 of 5 tuning:     linear_reg_confirmed_elastic_net_wf (1m 18.2s)
# i 5 of 5 tuning:     pls_confirmed_model_wf
# v 5 of 5 tuning:     pls_confirmed_model_wf (1m 29.2s)

stopCluster(cl)

# saveRDS(workflow_results_confirmed, "workflow_results_confirmed.RDS")
```


```{r}
# Updating the set of tuning parameters for DEATHS
# With the commented lines, we get the current best parameter, and we make a grid
# around them
# workflow_results_deaths %>% 
#   pull_workflow_set_result("linear_reg_deaths_ridge_wf") %>% 
#   select_best(metric = "rmse") 
ridge_param <- ridge_model %>%
  parameters() %>%
  update(penalty = penalty(c(1.293592e-10-1e-10, 1.293592e-10+1e-10)))
# workflow_results_deaths %>% 
#   pull_workflow_set_result("linear_reg_deaths_lasso_wf") %>% 
#   select_best(metric = "rmse")
lasso_param <- lasso_model %>%
  parameters() %>%
  update(penalty = penalty(c(1.293592e-10-1e-10, 1.293592e-10+1e-10)))
# workflow_results_deaths %>% 
#   pull_workflow_set_result("linear_reg_deaths_elastic_net_wf") %>%
#   select_best(metric = "rmse")
en_param <- elastic_net_model %>%
  parameters() %>%
  update(penalty = penalty(c(2.050205e-08-1e-8, 2.050205e-08+1e-8)),
         mixture = mixture(c(0.991625-0.005, 0.991625+0.005)))
# workflow_results_deaths %>% 
#  pull_workflow_set_result("pls_deaths_model_wf") %>% 
#  select_best(metric = "rmse")
pls_param <- pls_model %>%
  parameters() %>%
  update(predictor_prop = predictor_prop(c(0.09556132-0.05, 0.09556132+0.05)),
         num_comp = num_comp(c(2-1, 2+3)))
  
# After that, we add them to the workflow
workflow_tune_deaths <- workflow_tune_deaths %>%
  option_add(param_info = ridge_param, id = "linear_reg_deaths_ridge_wf") %>%
  option_add(param_info = lasso_param, id = "linear_reg_deaths_lasso_wf") %>%
  option_add(param_info = en_param, id = "linear_reg_deaths_elastic_net_wf") %>%
  option_add(param_info = pls_param, id = "pls_deaths_model_wf")
```

```{r, eval=F}
# And we tune again our models:
# DEATHS
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      save_workflow = TRUE
   )

workflow_results_deaths_tuned <- workflow_tune_deaths %>%
  workflow_map(
    seed = 1503,
    resamples = spain_rolling_deaths,
    grid = 50,
    control = grid_ctrl,
    verbose = T
   )


# i	No tuning parameters. `fit_resamples()` will be attempted
# i 1 of 5 resampling: linear_reg_deaths_lm_wf
# v 1 of 5 resampling: linear_reg_deaths_lm_wf (10s)
# i 2 of 5 tuning:     linear_reg_deaths_ridge_wf
# v 2 of 5 tuning:     linear_reg_deaths_ridge_wf (3s)
# i 3 of 5 tuning:     linear_reg_deaths_lasso_wf
# v 3 of 5 tuning:     linear_reg_deaths_lasso_wf (2.6s)
# i 4 of 5 tuning:     linear_reg_deaths_elastic_net_wf
# v 4 of 5 tuning:     linear_reg_deaths_elastic_net_wf (1m 6.7s)
# i 5 of 5 tuning:     pls_deaths_model_wf
# v 5 of 5 tuning:     pls_deaths_model_wf (1m 10.8s)

# saveRDS(workflow_results_deaths_tuned, "workflow_results_deaths_tuned.RDS")
```


```{r}
# Updating the set of tuning parameters for CONFIRMED
# With the commented lines, we get the current best parameter, and we make a grid
# around them
# workflow_results_confirmed %>% 
#   pull_workflow_set_result("linear_reg_confirmed_ridge_wf") %>% 
#   select_best(metric = "rmse") 
ridge_param <- ridge_model %>%
  parameters() %>%
  update(penalty = penalty(c(1.538034e-10-1e-10, 1.538034e-10+1e-10)))
# workflow_results_confirmed %>% 
#   pull_workflow_set_result("linear_reg_confirmed_lasso_wf") %>% 
#   select_best(metric = "rmse")
lasso_param <- lasso_model %>%
  parameters() %>%
  update(penalty = penalty(c(1.538034e-10-1e-10, 1.538034e-10+1e-10)))
# workflow_results_confirmed %>% 
#  pull_workflow_set_result("linear_reg_confirmed_elastic_net_wf") %>% 
#  select_best(metric = "rmse")
en_param <- elastic_net_model %>%
  parameters() %>%
  update(penalty = penalty(c(5.159664e-08-1e-8, 5.159664e-08+1e-8)),
         mixture = mixture(c(0.05609091-0.01, 0.05609091+0.01)))
# workflow_results_confirmed %>% 
#  pull_workflow_set_result("pls_confirmed_model_wf") %>% 
#  select_best(metric = "rmse")
pls_param <- pls_model %>%
  parameters() %>%
  update(predictor_prop = predictor_prop(c(0.6095881-0.05, 0.6095881+0.05)),
         num_comp = num_comp(c(2-1, 2+3)))
  
# After that, we add them to the workflow
workflow_tune_confirmed <- workflow_tune_confirmed %>%
  option_add(param_info = ridge_param, id = "linear_reg_confirmed_ridge_wf") %>%
  option_add(param_info = lasso_param, id = "linear_reg_confirmed_lasso_wf") %>%
  option_add(param_info = en_param, id = "linear_reg_confirmed_elastic_net_wf") %>%
  option_add(param_info = pls_param, id = "pls_confirmed_model_wf")
```

```{r, eval=F}
# CONFIRMED
cl <- makePSOCKcluster(8)
registerDoParallel(cl)

grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      save_workflow = TRUE
   )

workflow_results_confirmed_tuned <- workflow_tune_confirmed %>%
  workflow_map(
    seed = 1503,
    resamples = spain_rolling_confirmed,
    grid = 50,
    control = grid_ctrl,
    verbose = T
   )

# i	No tuning parameters. `fit_resamples()` will be attempted
# i 1 of 5 resampling: linear_reg_confirmed_lm_wf
# v 1 of 5 resampling: linear_reg_confirmed_lm_wf (9.2s)
# i 2 of 5 tuning:     linear_reg_confirmed_ridge_wf
# v 2 of 5 tuning:     linear_reg_confirmed_ridge_wf (3.2s)
# i 3 of 5 tuning:     linear_reg_confirmed_lasso_wf
# v 3 of 5 tuning:     linear_reg_confirmed_lasso_wf (2.3s)
# i 4 of 5 tuning:     linear_reg_confirmed_elastic_net_wf
# v 4 of 5 tuning:     linear_reg_confirmed_elastic_net_wf (1m 4.3s)
# i 5 of 5 tuning:     pls_confirmed_model_wf
# v 5 of 5 tuning:     pls_confirmed_model_wf (1m 8.5s)

stopCluster(cl)

# saveRDS(workflow_results_confirmed_tuned, "workflow_results_confirmed_tuned.RDS")
```

```{r, eval=F}
# Finally, we add the rlm workflow to the original:

workflow_results_deaths_tuned <-
  as_workflow_set(linear_reg_deaths_rlm_wf = rlm_deaths_resamples) %>%
  bind_rows(workflow_results_deaths_tuned)

workflow_results_confirmed_tuned <-
  as_workflow_set(linear_reg_confirmed_rlm_wf = rlm_confirmed_resamples) %>%
  bind_rows(workflow_results_confirmed_tuned)

# saveRDS(workflow_results_deaths_tuned, "workflow_results_deaths_tuned.RDS")
# saveRDS(workflow_results_confirmed_tuned, "workflow_results_confirmed_tuned.RDS")
```


```{r}
workflow_results_deaths_tuned <- readRDS("../02_results/workflow_results_deaths_tuned.RDS")
workflow_results_confirmed_tuned <- readRDS("../02_results/workflow_results_confirmed_tuned.RDS")
```




```{r, fig.cap="Results for the deaths models"}
# workflow_results_deaths_tuned %>%
#   rank_results(select_best = T) %>%
#   filter(.metric == "rmse")

# workflow_results_confirmed_tuned %>%
#   rank_results(select_best = T) %>%
#   filter(.metric == "rsq")

autoplot(workflow_results_deaths_tuned, select_best = T) +
  ggtitle("Results for the deaths model") +
  theme(plot.title = element_text(hjust = 0.5, size = 20)) +
  scale_color_tq() +
  theme_tq()
```

As we can observe above, there is a big difference between the partial least squares
model and the rest. The mean for the RMSE is around 100, i.e., the mean error is
around 100 deaths, and the RSE is around 0.9. Both of these metrics have a very 
good results. In the same way, as we can see for the models of confirmed cases,
the one with the best metrics is also the partial least squares, which its RMSE
is below 10000 and the RSE is again close to 0.9.


```{r, fig.cap="Results for the confirmed cases models"}
autoplot(workflow_results_confirmed_tuned, select_best = T) +
  scale_color_tq() +
  ggtitle("Results for the confirmed cases models") +
  theme(plot.title = element_text(hjust = 0.5, size = 20)) +
  theme_tq()
```

# MODEL SELECTION AND CONCLUSIONS 

As we have seen in the previous chapter, the best model for both cases is the 
**Partial Least Squares (PLS) regression**. As we briefly described before, it is
a statistical method that is related with the principal components regression. It
reduces the predictors to a smaller set of uncorrelated components and perform 
least squares regression with these components instead of using the original data.
For both models, we can observe the final parameters:


|  **Model**    |`predictor_prop`|`num_comp`|
|---------------|:--------------:|:--------:|
|Deaths         |     0.1344     |3         |
|Confirmed cases|     0.5607     |2         |
:Final set of parameters for each model


The first parameter, `predictor_prop`, indicates the proportion of variables that
are used in every PLS component. Since we have 24 predictors after the preprocessing,
4 and 13 variables are used on each of the sPLS components. The second parameter 
indicates the number of PLS components that are used as predictors in each model.

Consecutively, we have to *finalize* the workflows, i.e., we have to give the best
set of parameters to each model. And now, we are able to fit the model 
**in all the training set**, since the previous folds were used only to get these
parameters.


```{r}
# Deaths
best_results_deaths <- 
   workflow_results_deaths_tuned %>% 
   pull_workflow_set_result("pls_deaths_model_wf") %>% 
   select_best(metric = "rmse")


best_workflow_deaths <- 
   workflow_results_deaths_tuned %>% 
   pull_workflow("pls_deaths_model_wf") %>% 
   finalize_workflow(best_results_deaths)

# Confirmed
best_results_confirmed <- 
   workflow_results_confirmed_tuned %>% 
   pull_workflow_set_result("pls_confirmed_model_wf") %>% 
   select_best(metric = "rmse")


best_workflow_confirmed <- 
   workflow_results_confirmed_tuned %>% 
   pull_workflow("pls_confirmed_model_wf") %>% 
   finalize_workflow(best_results_confirmed)
```

```{r, results='hide'}
best_fit_deaths <- best_workflow_deaths %>%
  fit(spain)

best_fit_confirmed <- best_workflow_confirmed %>%
  fit(spain)
```

After fitting the models, in order to see some characteristics of them, we can plot
a *Correlation Circle Plot*, which represents the two components and projects the 
variables in the plane defined by them. Strongly associated or correlated variables
are plotted in the same direction. The greater the distance from the origin the 
stronger the association. For the deaths model, we can observe two main groups whose
variables are very correlated with the outcome. 

```{r, fig.width=9, fig.cap="Correlation Circle Plot for the deaths model"}
plotVar(best_fit_deaths$fit$fit$fit)
```


After analyzing the characteristics of the best models, we are going to see the 
predictive power of the models in the training and testing sets. Below we can
observe the difference between the observed and predicted values for both variables
deaths and confirmed cases per week:

```{r, fig.width=9}
pred_train_deaths <- best_fit_deaths %>%
  predict(new_data = spain)

p1 <- spain %>%
  mutate(predictions = pred_train_deaths$.pred) %>%
  dplyr::select(date, deaths_week, predictions) %>%
  pivot_longer(cols = c("deaths_week", "predictions"), values_to = "value", names_to = "Variable") %>%
  ggplot(aes(x = date, y = value)) +
  geom_line(aes(color = Variable), size = 1) +
  scale_color_manual(values = c("darkred", "steelblue")) +
  labs(
    y = "Deaths per week",
    x = "Date"
  ) 

pred_train_confirmed <- best_fit_confirmed %>%
  predict(new_data = spain)

p2 <- spain %>%
  mutate(predictions = pred_train_confirmed$.pred) %>%
  dplyr::select(date, confirmed_week, predictions) %>%
  pivot_longer(cols = c("confirmed_week", "predictions"), values_to = "value", names_to = "Variable") %>%
  ggplot(aes(x = date, y = value)) +
  geom_line(aes(color = Variable), size = 1) +
  scale_color_manual(values = c("darkred", "steelblue")) +
  labs(
    y = "Confirmed cases per week",
    x = "Date"
  ) 

ggarrange(p1, p2) +
  ggtitle("Results in the train set for both models") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))
```

Even though the predictions are very similar to the real values, we cannot reach
the peaks of deaths that appear in April or February, and the peak of confirmed 
cases of February. This happen because we want to predict the following three weeks,
so we are considering 3 lagged variables. If we wanted to predict only the next 
week, we would consider the value of deaths and confirmed cases of the day before,
so we would have a much more accurate model.

In the testing set we have the following results:
```{r}
pred_test_deaths <- best_fit_deaths %>%
  predict(new_data = spain_new_data)

pred_test_confirmed <- best_fit_confirmed %>%
  predict(new_data = spain_new_data)

results <- spain_new_data %>%
  mutate(
    predicted_deaths = pred_test_deaths$.pred,
    predicted_confirmed = pred_test_confirmed$.pred
  ) %>%
  dplyr::select(date, deaths_week, predicted_deaths, confirmed_week, predicted_confirmed) %>%
  summarise(
    Date = date,
    Deaths = deaths_week, 
    `Predicted Deaths` = round(predicted_deaths, digits = 0),
    `Difference Deaths` = abs(Deaths - `Predicted Deaths`),
    Confirmed = confirmed_week, 
    `Predicted Confirmed` = round(predicted_confirmed, digits = 0),
    `Difference Confirmed` = abs(Confirmed - `Predicted Confirmed`)
  )

knitr::kable(results, caption = "Results in the testing set")
```

\newpage
# REFERENCES
